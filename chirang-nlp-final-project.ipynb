{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install Keras-Preprocessing\n!pip install rouge-score","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:59:00.391323Z","iopub.execute_input":"2023-05-06T00:59:00.391691Z","iopub.status.idle":"2023-05-06T00:59:21.146217Z","shell.execute_reply.started":"2023-05-06T00:59:00.391661Z","shell.execute_reply":"2023-05-06T00:59:21.145070Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Requirement already satisfied: Keras-Preprocessing in /opt/conda/lib/python3.10/site-packages (1.1.2)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from Keras-Preprocessing) (1.23.5)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from Keras-Preprocessing) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.23.5)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24954 sha256=c1f126387f1a5ee171029174cfa0bf8c3654bfc61a2e8b2d48eed7302064bf8d\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"Imports","metadata":{}},{"cell_type":"code","source":"from keras_preprocessing.sequence import pad_sequences\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nimport keras.utils as ku \nimport pandas as pd\nimport numpy as np\nimport string, os \nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:24:15.142392Z","iopub.execute_input":"2023-05-06T00:24:15.142723Z","iopub.status.idle":"2023-05-06T00:24:21.249730Z","shell.execute_reply.started":"2023-05-06T00:24:15.142690Z","shell.execute_reply":"2023-05-06T00:24:21.248343Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"from bs4 import BeautifulSoup","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:24:21.251046Z","iopub.execute_input":"2023-05-06T00:24:21.251791Z","iopub.status.idle":"2023-05-06T00:24:21.443537Z","shell.execute_reply.started":"2023-05-06T00:24:21.251739Z","shell.execute_reply":"2023-05-06T00:24:21.442664Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Load Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\ncombined_df = pd.read_csv('/kaggle/input/jobs-dataset/jd/job_descriptions_Marketing Intern.csv', usecols = ['description'], nrows=100)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:24:21.445756Z","iopub.execute_input":"2023-05-06T00:24:21.446390Z","iopub.status.idle":"2023-05-06T00:24:21.496879Z","shell.execute_reply.started":"2023-05-06T00:24:21.446355Z","shell.execute_reply":"2023-05-06T00:24:21.496020Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"HTML cleaning","metadata":{}},{"cell_type":"code","source":"for index in range(len(combined_df['description'])):\n    html_string = combined_df['description'][index]\n    soup = BeautifulSoup(html_string, \"html.parser\")\n    combined_df['description'][index] = soup.get_text()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:24:21.512405Z","iopub.execute_input":"2023-05-06T00:24:21.513162Z","iopub.status.idle":"2023-05-06T00:24:21.759729Z","shell.execute_reply.started":"2023-05-06T00:24:21.513130Z","shell.execute_reply":"2023-05-06T00:24:21.758852Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"all_descriptions = list(combined_df.description.values)\nlen(all_descriptions)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:24:21.769984Z","iopub.execute_input":"2023-05-06T00:24:21.770742Z","iopub.status.idle":"2023-05-06T00:24:21.780183Z","shell.execute_reply.started":"2023-05-06T00:24:21.770709Z","shell.execute_reply":"2023-05-06T00:24:21.779313Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"100"},"metadata":{}}]},{"cell_type":"markdown","source":"Filtered Data","metadata":{}},{"cell_type":"code","source":"corpus = [x for x in all_descriptions]\ncorpus[:1]","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:24:21.781260Z","iopub.execute_input":"2023-05-06T00:24:21.781497Z","iopub.status.idle":"2023-05-06T00:24:21.790989Z","shell.execute_reply.started":"2023-05-06T00:24:21.781476Z","shell.execute_reply":"2023-05-06T00:24:21.790056Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[\"Marketing Intern (Summer 2022)\\nTake your next career step at ABB with a global team that is energizing the transformation of society and industry to achieve a more productive, sustainable future. At ABB, we have the clear goal of driving diversity and inclusion across all dimensions: gender, LGBTQ+, abilities, ethnicity and generations. Together, we are embarking on a journey where each and every one of us, individually and collectively, welcomes and celebrates individual differences.\\nABB’s Electrification organization is responsible for the go-to-market strategy and generating profitable growth for the Electrification Business Area. Our 10,000 strong commercial team represents the portfolio of all Electrification Business Area Divisions in over 100 countries. Our unmatched domain expertise across key industry verticals and channels combined with our truly global footprint makes us able to deliver extraordinary business results, supporting our customers with solutions which address their current needs, whilst considering the future emerging trends such as Urbanization, Digitalization and Shift to Electricity and Sustainable Energy. Our Marketing teams play a key role in how ABB’s technologies contribute to a more productive and sustainable future. Helping customers all over the world improve efficiency, reliability and productivity while reducing emissions gives our work a powerful sense of purpose.\\nYour responsibilities\\nWork with Sales and Marketing Manager to exe-cute yearly and 5-year growth plans.\\nDevelop Marketing materials; print, social media platforms, presentations etc.\\nAssist in the launch and acceptance of Install Base tracking tools.\\nManage Install Base data and extract pertinent market data to assist in offer development, competitor analyses and lead generation.\\nLead all social media advertising and promotion. Develop materials and train sales team on usage.\\nCoordinate and participate in promotional activities and trade shows to market products and services as required.\\nStrong safety focus and safety attitude required at all times.\\nYour background\\nRespective education in Marketing.\\nKnowledge of the electrical industry would be an asset.\\nWillingness to learn and be creative.\\nAble to work independent and as a team.\\nSound written and verbal communication skills.\\nBilingual in French and English would be an asset.\\nOpen to new ideas while drawing on proven experience and successes.\\nAbility to work in a deadline driven environment, where growth plan is 10% year over year.\\nMore about us\\nWe look forward to receiving your application. If you want to discover more about ABB, take another look at our website www.abb.com. For the 4th year in a row, ABB Canada has been recognized as one of Canada’s top employers by Forbes Magazine and has been ranked #1 within the industry category. Also named as Canada's Top 100 Employers, Montreal's Top Employers, Canada's Top Employers for Young People, and Best Candidate Experience Award (CandE Award), ABB's culture and commitment are to provide a caring workplace where everyone collaborates, feels valued, respected, included and supported. Also committed to ensuring that all policies and practices respect the Employment Equity Program, we aim for our workforce to be truly representative of the four designated groups; women, aboriginal people, members of visible minorities, and/or persons with disabilities. ABB will provide reasonable accommodation to the applicant with disabilities and encourage applicants to self-identify in the application process. #LI-Hybrid\"]"},"metadata":{}}]},{"cell_type":"code","source":"# print(t.word_counts)\n# print(t.word_docs)\n# print(t.document_count)\n# print(t.word_index)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:24:21.794430Z","iopub.execute_input":"2023-05-06T00:24:21.794744Z","iopub.status.idle":"2023-05-06T00:24:21.799373Z","shell.execute_reply.started":"2023-05-06T00:24:21.794722Z","shell.execute_reply":"2023-05-06T00:24:21.798273Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Tokenization","metadata":{}},{"cell_type":"code","source":"t = Tokenizer(num_words=vocabulary_size, filters='\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0)\n\ndef get_sequence_of_tokens(corpus):\n    t.fit_on_texts(corpus)\n    print('Found %s unique tokens.' % len(t.word_index))\n    total_words = len(t.word_index) + 1\n    \n    input_sequences = []\n    for line in corpus:\n        token_list = t.texts_to_sequences([line])[0]\n        for i in range(1, len(token_list)):\n            n_gram_sequence = token_list[:i+1]\n            input_sequences.append(n_gram_sequence)\n            \n    return input_sequences, total_words\ninput_sequences, total_words = get_sequence_of_tokens(corpus)\ninput_sequences[:10]","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:24:21.808336Z","iopub.execute_input":"2023-05-06T00:24:21.808824Z","iopub.status.idle":"2023-05-06T00:24:22.100528Z","shell.execute_reply.started":"2023-05-06T00:24:21.808795Z","shell.execute_reply":"2023-05-06T00:24:22.099656Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Found 7610 unique tokens.\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[[9, 52],\n [9, 52, 3366],\n [9, 52, 3366, 3367],\n [9, 52, 3366, 3367, 331],\n [9, 52, 3366, 3367, 331, 29],\n [9, 52, 3366, 3367, 331, 29, 592],\n [9, 52, 3366, 3367, 331, 29, 592, 123],\n [9, 52, 3366, 3367, 331, 29, 592, 123, 1703],\n [9, 52, 3366, 3367, 331, 29, 592, 123, 1703, 32],\n [9, 52, 3366, 3367, 331, 29, 592, 123, 1703, 32, 1704]]"},"metadata":{}}]},{"cell_type":"markdown","source":"Pad Sequences","metadata":{}},{"cell_type":"code","source":"def generate_padded_sequences(input_sequences):\n    max_sequence_len = max([len(x) for x in input_sequences])\n    input_sequences = np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding = 'pre'))\n    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n    label = ku.to_categorical(label, num_classes = total_words)\n    \n    return predictors, label, max_sequence_len\n\npredictors, label, max_sequence_len = generate_padded_sequences(input_sequences)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:24:22.102116Z","iopub.execute_input":"2023-05-06T00:24:22.102466Z","iopub.status.idle":"2023-05-06T00:24:22.927403Z","shell.execute_reply.started":"2023-05-06T00:24:22.102436Z","shell.execute_reply":"2023-05-06T00:24:22.926473Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"W2V Embeddings Load","metadata":{}},{"cell_type":"code","source":"from gensim.models.keyedvectors import KeyedVectors\nembs_path = '/kaggle/input/wikinews/wiki-news-300d-1M-subword.vec'\nembeddings = KeyedVectors.load_word2vec_format(embs_path, binary=False)\ndim = embeddings.vectors.shape[1]\npad = np.zeros(dim)\nnp.random.seed(3)\noov = np.random.uniform(-0.25, 0.25, dim)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:24:22.928960Z","iopub.execute_input":"2023-05-06T00:24:22.929328Z","iopub.status.idle":"2023-05-06T00:27:24.988008Z","shell.execute_reply.started":"2023-05-06T00:24:22.929295Z","shell.execute_reply":"2023-05-06T00:27:24.987077Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"W2V weight matrix","metadata":{}},{"cell_type":"code","source":"embedding_matrix_w2v = np.zeros((vocabulary_size, 300))\nfor word, index in t.word_index.items():\n    if index > vocabulary_size - 1:\n        break\n    else:\n        try:\n            embedding_vector = embeddings[word]\n            if embedding_vector is not None:\n                embedding_matrix_w2v[index] = embedding_vector\n        except:\n            embedding_matrix_w2v[index] = oov","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:27:24.990447Z","iopub.execute_input":"2023-05-06T00:27:24.991170Z","iopub.status.idle":"2023-05-06T00:27:25.045443Z","shell.execute_reply.started":"2023-05-06T00:27:24.991116Z","shell.execute_reply":"2023-05-06T00:27:25.044599Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Model definition","metadata":{}},{"cell_type":"code","source":"def create_model(max_sequence_len, total_words):\n    model = Sequential()\n    \n    # Add Input Embedding Layer\n    model.add(Embedding(vocabulary_size, 300, input_length=max_sequence_len-1, weights=[embedding_matrix_w2v]))\n    \n    # Add Hidden Layer 1 - LSTM Layer\n    model.add(LSTM(100))\n    model.add(Dropout(0.2))\n    \n    # Add Output Layer\n    model.add(Dense(total_words, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    \n    return model\n\nmodel = create_model(max_sequence_len, total_words)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T14:23:14.855292Z","iopub.execute_input":"2023-05-05T14:23:14.855629Z","iopub.status.idle":"2023-05-05T14:23:15.128138Z","shell.execute_reply.started":"2023-05-05T14:23:14.855601Z","shell.execute_reply":"2023-05-05T14:23:15.127350Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_2 (Embedding)     (None, 986, 300)          3000000   \n                                                                 \n lstm_2 (LSTM)               (None, 100)               160400    \n                                                                 \n dropout_2 (Dropout)         (None, 100)               0         \n                                                                 \n dense_2 (Dense)             (None, 7611)              768711    \n                                                                 \n=================================================================\nTotal params: 3,929,111\nTrainable params: 3,929,111\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Load model","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nmodel = keras.models.load_model('/kaggle/working/w2v_100')","metadata":{"execution":{"iopub.status.busy":"2023-05-06T01:26:35.092979Z","iopub.execute_input":"2023-05-06T01:26:35.093357Z","iopub.status.idle":"2023-05-06T01:26:36.756884Z","shell.execute_reply.started":"2023-05-06T01:26:35.093325Z","shell.execute_reply":"2023-05-06T01:26:36.755941Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"Training","metadata":{}},{"cell_type":"code","source":"history = model.fit(predictors, label, epochs=100, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save Model","metadata":{}},{"cell_type":"code","source":"model.save('w2v_100')","metadata":{"execution":{"iopub.status.busy":"2023-05-05T17:45:48.275249Z","iopub.execute_input":"2023-05-05T17:45:48.275669Z","iopub.status.idle":"2023-05-05T17:45:53.492990Z","shell.execute_reply.started":"2023-05-05T17:45:48.275630Z","shell.execute_reply":"2023-05-05T17:45:53.492067Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"!zip -r w2v_100.zip /kaggle/working/w2v_100","metadata":{"execution":{"iopub.status.busy":"2023-05-05T17:45:53.495596Z","iopub.execute_input":"2023-05-05T17:45:53.495984Z","iopub.status.idle":"2023-05-05T17:45:56.481188Z","shell.execute_reply.started":"2023-05-05T17:45:53.495907Z","shell.execute_reply":"2023-05-05T17:45:56.480066Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/w2v_100/ (stored 0%)\n  adding: kaggle/working/w2v_100/variables/ (stored 0%)\n  adding: kaggle/working/w2v_100/variables/variables.data-00000-of-00001 (deflated 23%)\n  adding: kaggle/working/w2v_100/variables/variables.index (deflated 56%)\n  adding: kaggle/working/w2v_100/assets/ (stored 0%)\n  adding: kaggle/working/w2v_100/fingerprint.pb (stored 0%)\n  adding: kaggle/working/w2v_100/keras_metadata.pb (deflated 87%)\n  adding: kaggle/working/w2v_100/saved_model.pb (deflated 90%)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Generate Text","metadata":{}},{"cell_type":"code","source":"def generate_text(seed_text, next_words, model, max_seq_len):\n    for _ in range(next_words):\n        token_list = t.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n        \n        predict_x=model.predict(token_list)\n        predicted=np.argmax(predict_x,axis=1)\n#         predicted = model.predict_classes(token_list, verbose=0)\n        \n        output_word = ''\n        \n        for word,index in t.word_index.items():\n            if index == predicted:\n                output_word = word\n                break\n                \n        seed_text = seed_text + \" \" + output_word\n        \n    return seed_text.title()","metadata":{"execution":{"iopub.status.busy":"2023-05-06T00:33:48.352524Z","iopub.execute_input":"2023-05-06T00:33:48.353369Z","iopub.status.idle":"2023-05-06T00:33:48.363668Z","shell.execute_reply.started":"2023-05-06T00:33:48.353321Z","shell.execute_reply":"2023-05-06T00:33:48.362675Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"gen = generate_text(\"september\", 100, model, max_sequence_len)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T03:44:11.133103Z","iopub.execute_input":"2023-05-06T03:44:11.133465Z","iopub.status.idle":"2023-05-06T03:44:16.952513Z","shell.execute_reply.started":"2023-05-06T03:44:11.133437Z","shell.execute_reply":"2023-05-06T03:44:16.951682Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 35ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 27ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 26ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 24ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 23ms/step\n1/1 [==============================] - 0s 25ms/step\n1/1 [==============================] - 0s 24ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"gen","metadata":{"execution":{"iopub.status.busy":"2023-05-06T03:44:19.404919Z","iopub.execute_input":"2023-05-06T03:44:19.405282Z","iopub.status.idle":"2023-05-06T03:44:19.411289Z","shell.execute_reply.started":"2023-05-06T03:44:19.405253Z","shell.execute_reply":"2023-05-06T03:44:19.410439Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"'September 2022 - ( 220001G0 ) Description Is - The New Company Event That The Next Generation. And Be Better World. From Shared Your Services Through Our Community Manager To Ensure The Photo Team To Bring The Company. Other Hospital Stakeholders At All Levels. Ability To Work Independently And Efficiently In A Busy Environment Managing Multiple Projects, Shifting Priorities, And Tight Deadlines. Canada Summer Jobs Program Requirements: Placement Is Full Time Only (35 Hours Per Week) With A Minimum Duration Of Six Weeks And A Maximum Of 16 Weeks Placement Must Occur Between April 25, 2022 And September 3, 2022 Applicants'"},"metadata":{}}]},{"cell_type":"code","source":"from rouge_score import rouge_scorer\nimport numpy as np\n\ndef calculate_rouge_score(target, predicted):\n    '''\n    target:    a list of strings containing the summarizations as the ground truth\n    predicted: a list of strings containing the summarizations from the model\n    '''\n\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)\n    rouge1_f1_scores = []\n    rouge2_f1_scores = []\n    rougeL_f1_scores = []\n    rougeLsum_f1_scores = []\n    for i in range(len(predicted)):\n        scores = scorer.score(target[i], predicted[i])\n        rouge1_f1_scores.append(scores['rouge1'][2])\n        rouge2_f1_scores.append(scores['rouge2'][2])\n        rougeL_f1_scores.append(scores['rougeL'][2])\n        rougeLsum_f1_scores.append(scores['rougeLsum'][2])\n    \n    return {'rouge1': np.array(rouge1_f1_scores).mean(),\n          'rouge2': np.array(rouge2_f1_scores).mean(),\n          'rougeL': np.array(rougeL_f1_scores).mean(),\n          'rougeLsum': np.array(rougeLsum_f1_scores).mean()}","metadata":{"execution":{"iopub.status.busy":"2023-05-06T01:00:31.834407Z","iopub.execute_input":"2023-05-06T01:00:31.834805Z","iopub.status.idle":"2023-05-06T01:00:31.844693Z","shell.execute_reply.started":"2023-05-06T01:00:31.834774Z","shell.execute_reply":"2023-05-06T01:00:31.843731Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"corpus[1].replace('\\n', '')","metadata":{"execution":{"iopub.status.busy":"2023-05-06T02:14:05.839785Z","iopub.execute_input":"2023-05-06T02:14:05.840248Z","iopub.status.idle":"2023-05-06T02:14:05.852513Z","shell.execute_reply.started":"2023-05-06T02:14:05.840212Z","shell.execute_reply":"2023-05-06T02:14:05.851584Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"'Marketing InternThe MRG Group - HospitalityOttawa,ONThe MRG Group is looking for a Marketing Intern to join our team and gain valuable experience that pertains to their studies.The MRG Group is an industry leader in concerts, hospitality, live entertainment, lifestyle and events. Our mission is to create Positive Shareable Experiences for everyone involved with our businesses.The MRG Group by the numbers in 2021:8 Hospitality Properties across Canada1000+ live shows per year via the largest Independent Concert Promotions Company in Canada, MRG Live5 Live Entertainment Venues10+ Large Scale Events per year (2019)MRG Travel - Curating Travel ExperiencesAdmit One - Ticketing PlatformBeatroute - Global lifestyle digital media companyAs an important part of the marketing team, you will be responsible for assisting the hospitality marketing team with executing marketing and social media initiatives for properties in Ottawa, The Prescott and Par Tee Putt.Reporting into the Hospitality Marketing Manager, the Marketing Intern will be responsible for:RESPONSIBILITIES:Working as a part of the hospitality team to implement marketing and social media activitiesWorking collaboratively with the social media coordinator on researching, writing and curating social media posts and email communications and regularly capturing content within our local venuesRegularly communicate and work collaboratively with our local Operations Manager to ensure we are meeting all of their marketing needsProactively developing relationships with potential partners and actively pitching to all media outlets and influencers in OttawaServing as the point of contact for influencer relationsCoordinating events and executing for assigned venuesGenerating reports and analytics that measure the success of marketing initiatives, projects, event recaps, etc.Building and maintaining social calendarsDrafting email newsletters for assigned venuesEnsuring you are in the know of all events happening in the city, as well as sports games, concerts, etcMUST HAVES:Enrolled in an undergraduate or graduate program at a post-secondary educational institutionA focus on marketing, events, social media or communications is considered an assetInternship is full-time, qualified candidates will be available for 40 hours/weekAbility to work under pressure and prioritize multiple requests and projects while maintaining close attention to detail and accuracyStrong organizational skillsAbility to work independently, as well as part of a teamExperience with Microsoft Excel, PowerPoint and/or Google DocsAvailable evenings and/or weekends, as requiredAccess to a computer/laptopWe thank all applicants for their interest, however only those selected will be contacted.WHO WE ARE:In operation since 2008 with the reopening of the historic Vogue Theatre in Vancouver, Canada, The MRG Group has grown into one of the leading entertainment and hospitality companies in Canada. Owning and operating a total of 13 properties across the country, MRG’s hospitality venues include Yale Saloon and Dublin Calling on Granville Street in Vancouver, The Porch, Par Tee Putt and Rock ‘N’ Horse in the heart of downtown Toronto. MRG’s mission is to create positive shareable experiences for all who come in contact with the venues and events. With offices in Toronto, New York, Miami, Vancouver, Victoria, and Montreal, MRG LIVE is currently the largest independent concert and event promoter in Canada. MRG expanded into media in 2019, with the acquisition of BeatRoute with the intention of supporting and celebrating the local and global music and cultural communities.Job Types: Full-time, Internship / Co-opContract length: 4 monthsSchedule:8 hour shiftApplication question(s):Are you on the path to obtaining full vaccination against COVID-19, or are you medically exempt under the law? (Note: Proof of vaccination or medical exemption will be required for this position)Are you eligible to legally work in Canada?Are comfortable attaining a background check for this position?Describe an ideal night out?What is your desired salary?'"},"metadata":{}}]},{"cell_type":"code","source":"calculate_rouge_score(corpus[1], gen)","metadata":{"execution":{"iopub.status.busy":"2023-05-06T01:04:25.928561Z","iopub.execute_input":"2023-05-06T01:04:25.928918Z","iopub.status.idle":"2023-05-06T01:04:25.998470Z","shell.execute_reply.started":"2023-05-06T01:04:25.928892Z","shell.execute_reply":"2023-05-06T01:04:25.997471Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 0.044170890658942794,\n 'rouge2': 0.0,\n 'rougeL': 0.044170890658942794,\n 'rougeLsum': 0.044170890658942794}"},"metadata":{}}]}]}